{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Market basket analysis is a technique used by retailers to identify the relationships between items that customers frequently purchase together. Using association rules, retailers can predict the likelihood of purchasing certain products together, which can be used for product placement, cross-selling, or personalized recommendations.\n",
    "\n",
    "In this use case, we will perform Market Basket Analysis on a transactional dataset using association rule mining. The goal is to discover patterns or associations between items that are frequently bought together. We will use the Apriori Algorithm to generate association rules from the transactional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "The dataset consists of transactional data from a retail store. Each transaction contains a list of items purchased by customers. This data is organized as:\n",
    "\n",
    "- Transaction ID: A unique identifier for each purchase.\n",
    "- Items: The list of items purchased in each transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to be Covered\n",
    "\n",
    "### 1. Problem Definition\n",
    "Define the problem of identifying frequent itemsets and generating association rules to recommend or understand items frequently purchased together.\n",
    "\n",
    "### 2. Loading and Exploring the Dataset\n",
    "- Load the transactional dataset using `pandas`.\n",
    "- Explore the dataset structure, count of transactions, and unique items involved.\n",
    "- Preprocess the dataset to a suitable format for association rule mining.\n",
    "\n",
    "### 3. Data Preprocessing\n",
    "- Convert the transactional data into a suitable structure for the Apriori algorithm (e.g., converting the transactional data into a one-hot encoded format).\n",
    "- Ensure the data is clean and correctly formatted for the analysis.\n",
    "\n",
    "### 4. Apply Apriori Algorithm\n",
    "- Use the **Apriori algorithm** to identify frequent itemsets with a minimum support threshold.\n",
    "- Analyze and interpret the results, identifying the most frequently occurring item combinations.\n",
    "\n",
    "### 5. Generate Association Rules\n",
    "- Apply the **Association Rule Mining** technique on the frequent itemsets using a confidence threshold.\n",
    "- Calculate key metrics such as support, confidence, and lift for each rule.\n",
    "- Extract meaningful insights from the rules, such as which items are frequently purchased together.\n",
    "\n",
    "### 6. Interpretation of Results\n",
    "- Interpret the association rules, focusing on items that have high support and confidence.\n",
    "- Highlight any interesting patterns, such as which items are often bought together or which product combinations can drive cross-selling opportunities.\n",
    "\n",
    "### 7. Conclusion and Business Impact\n",
    "- Summarize the findings from the analysis.\n",
    "- Suggest potential strategies for product placement, bundling, or recommendation systems based on the discovered rules.\n",
    "- Discuss how the retail store can use these insights to improve sales or customer satisfaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('groceries_dataset.csv')\n",
    "\n",
    "# Preview the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "\n",
    "# Group items by Member_number and Date to create a list of transactions\n",
    "transactions = data.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).values.tolist()\n",
    "\n",
    "# Use TransactionEncoder to transform the list of transactions into a one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions).transform(transactions)\n",
    "df_transactions = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Preview the one-hot encoded DataFrame\n",
    "print(df_transactions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TransactionEncoder`: This is a tool from the mlxtend library that is used to perform one-hot encoding on the list of transactions.\n",
    "\n",
    "`One-hot encoding`: It converts the list of items into a binary format (0s and 1s), where:\n",
    "\n",
    "Each unique item is a column in the DataFrame.\n",
    "If an item is present in a particular transaction, it gets a '1' in the corresponding column; otherwise, it gets a '0'.\n",
    "This transformation makes the data suitable for algorithms like Apriori, which require transactional data in binary form.\n",
    "\n",
    "Example: If a transaction contains ['Milk', 'Bread'], the one-hot encoded format will look like this:\n",
    "\n",
    "| Milk | Bread | Butter | Beer |\n",
    "|------|-------|--------|------|\n",
    "|  1   |   1   |    0   |   0  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building (Apriori Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the minimum support threshold to 0.001\n",
    "frequent_itemsets = apriori(df_transactions, min_support=0.001, use_colnames=True)\n",
    "\n",
    "# Check for frequent itemsets\n",
    "if frequent_itemsets.empty:\n",
    "    print(\"No frequent itemsets found. Try lowering the support threshold.\")\n",
    "else:\n",
    "    print(\"Frequent Itemsets\")\n",
    "    print(frequent_itemsets.head())\n",
    "\n",
    "# Generate association rules with a lower confidence threshold (0.1)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# Check for rules\n",
    "if rules.empty:\n",
    "    print(\"No association rules found. Try lowering the confidence threshold.\")\n",
    "else:\n",
    "    print(\"Association Rules\")\n",
    "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1: Frequent Itemsets\n",
    "\n",
    "This table shows the **frequent itemsets** discovered by the Apriori algorithm. Each itemset is a combination of items that frequently appear together in transactions, along with their **support** value. The **support** represents the proportion of transactions in which that particular itemset appears.\n",
    "\n",
    "| Support  | Itemsets                  |\n",
    "|----------|---------------------------|\n",
    "| 0.004010 | (Instant food products)    |\n",
    "| 0.021386 | (UHT-milk)                 |\n",
    "| 0.001470 | (abrasive cleaner)         |\n",
    "| 0.001938 | (artificial sweetener)     |\n",
    "| 0.000807 | (baking powder)            |\n",
    "\n",
    "### Explanation of Columns:\n",
    "- **Support**: The percentage (or fraction) of total transactions in which an itemset occurs. It is a measure of how often an item or itemset appears in the dataset.\n",
    "  - Example: `UHT-milk` has a support value of **0.021386**, meaning it appears in about **2.14%** of all transactions in the dataset.\n",
    "\n",
    "- **Itemsets**: The groups of items that frequently appear together in transactions. For example, in many transactions, customers buy **UHT-milk**, so it appears as a frequent itemset.\n",
    "\n",
    "### Insights from Frequent Itemsets:\n",
    "- **High support values** indicate that an item or combination of items is popular among customers.\n",
    "  - Example: **UHT-milk** has the highest support value of **0.021386**, meaning it's one of the most commonly bought items.\n",
    "\n",
    "- **Low support values** show items that are bought less frequently but are still important if combined with other items to form meaningful associations.\n",
    "\n",
    "### Importance of Frequent Itemsets:\n",
    "- Frequent itemsets serve as the foundation for generating **association rules**. Once frequent itemsets are identified, we can analyze them further to discover rules that help in understanding customer purchasing behavior.\n",
    "\n",
    "\n",
    "#### Table 2: Association Rules\n",
    "\n",
    "This table presents the **association rules** generated from the frequent itemsets. Each rule indicates that when a certain item (or set of items, called the **antecedent**) is bought, another item (called the **consequent**) is likely to be bought as well. The table also provides key metrics for evaluating these rules:\n",
    "\n",
    "| Antecedents | Consequents       | Support | Confidence | Lift    |\n",
    "|-------------|-------------------|---------|------------|---------|\n",
    "| (UHT-milk)  | (other vegetables) | 0.002139 | 0.100000   | 0.818993 |\n",
    "| (UHT-milk)  | (whole milk)       | 0.002540 | 0.118750   | 0.751949 |\n",
    "| (beef)      | (whole milk)       | 0.004678 | 0.137795   | 0.872548 |\n",
    "| (berries)   | (other vegetables) | 0.002673 | 0.122699   | 1.004899 |\n",
    "| (berries)   | (whole milk)       | 0.002272 | 0.104294   | 0.660414 |\n",
    "\n",
    "### Key Metrics:\n",
    "- **Support**: The percentage of transactions that contain both the antecedent and the consequent.\n",
    "  - Example: The rule `(UHT-milk) -> (whole milk)` has a support of 0.002540, meaning both items are bought together in 0.25% of all transactions.\n",
    "  \n",
    "- **Confidence**: The probability that the consequent is purchased when the antecedent is purchased.\n",
    "  - Example: The rule `(beef) -> (whole milk)` has a confidence of 0.137795, meaning that when beef is purchased, there is about a 13.78% chance that whole milk is also purchased.\n",
    "  \n",
    "- **Lift**: The ratio of the observed support to the expected support if the items were independent. A lift greater than 1 implies a positive association between the antecedent and consequent (i.e., the items are more likely to be bought together).\n",
    "  - Example: The rule `(berries) -> (other vegetables)` has a lift of 1.004899, indicating that these items are slightly more likely to be bought together than if they were independent.\n",
    "\n",
    "### Summary:\n",
    "- **Frequent itemsets** show which items are often bought together.\n",
    "- **Association rules** help to understand the likelihood of certain items being bought together based on historical data.\n",
    "- **Support**, **confidence**, and **lift** are key metrics to assess how often items are bought together and how strong the associations are.\n",
    "\n",
    "These tables help businesses make decisions about product placement, bundling, and recommendations based on customer purchasing patterns.\n",
    "\n",
    "# Interpretation:\n",
    "- Higher support means that the itemset is more frequent in the transactions.\n",
    "- Higher confidence means that when the antecedent is purchased, the consequent is also purchased more frequently.\n",
    "- Lift > 1 suggests that the items are positively associated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the frequent itemsets and rules for later use\n",
    "import pickle\n",
    "\n",
    "# Save the frequent itemsets\n",
    "with open('frequent_itemsets.pkl', 'wb') as f:\n",
    "    pickle.dump(frequent_itemsets, f)\n",
    "\n",
    "# Save the association rules\n",
    "with open('association_rules.pkl', 'wb') as f:\n",
    "    pickle.dump(rules, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Using Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               antecedents         consequents   support  confidence      lift\n",
      "119   (yogurt, whole milk)  (other vegetables)  0.001136    0.101796  0.833705\n",
      "120  (whole milk, sausage)        (rolls/buns)  0.001136    0.126866  1.153275\n",
      "123   (yogurt, whole milk)        (rolls/buns)  0.001337    0.119760  1.088685\n",
      "126  (whole milk, sausage)              (soda)  0.001069    0.119403  1.229612\n",
      "127   (yogurt, whole milk)           (sausage)  0.001470    0.131737  2.182917\n",
      "129  (whole milk, sausage)            (yogurt)  0.001470    0.164179  1.911760\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model for predictions\n",
    "with open('association_rules.pkl', 'rb') as f:\n",
    "    loaded_rules = pickle.load(f)\n",
    "\n",
    "# Example: Predict products that are likely to be bought together\n",
    "# For demonstration, let's find the rules where the antecedent contains 'whole milk'\n",
    "milk_related_rules = loaded_rules[loaded_rules['antecedents'].apply(lambda x: 'whole milk' in str(x))]\n",
    "\n",
    "# Display the rules related to 'whole milk'\n",
    "print(milk_related_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
