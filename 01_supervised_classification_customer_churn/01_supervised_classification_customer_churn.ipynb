{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "Predicting whether a customer will churn (cancel their subscription) based on their behavior and account information using the Telco Customer Churn Dataset. The goal is to build a classification model that can accurately predict customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview:\n",
    "The dataset contains the following key features:\n",
    "\n",
    "- Demographics: gender, SeniorCitizen, Partner, Dependents\n",
    "- Account Information: tenure, PhoneService, MultipleLines, InternetService, Contract, PaymentMethod\n",
    "- Services: OnlineSecurity, DeviceProtection, TechSupport\n",
    "- Charges: MonthlyCharges, TotalCharges\n",
    "- Target: Churn (Yes/No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to be covered:\n",
    "- Data Preprocessing: Handle missing values, encode categorical variables, and split the dataset.\n",
    "- Model Training: Train a classification model using Random Forest.\n",
    "- Model Evaluation: Evaluate the model using accuracy and confusion matrix.\n",
    "- Save the Model: Save the trained model.\n",
    "- Load and Predict: Use the saved model for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas scikit-learn joblib imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the dataset provided by the user\n",
    "file_path = 'dataset_Telco-Customer-Churn.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "dataset.head()\n",
    "\n",
    "# Check the distribution of Churn in the original dataset\n",
    "print(\"Original dataset class distribution:\")\n",
    "print(dataset['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' to numeric, coercing errors to handle any non-numeric data\n",
    "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Handle missing values by filling 'TotalCharges' with 0\n",
    "dataset['TotalCharges'] = dataset['TotalCharges'].fillna(0)\n",
    "\n",
    "# Convert the 'Churn' column to binary (Yes -> 1, No -> 0)\n",
    "dataset['Churn'] = dataset['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Check the conversion\n",
    "print(dataset['Churn'].value_counts())\n",
    "\n",
    "# Select relevant features and target\n",
    "features = dataset.drop(columns=['customerID', 'Churn'])\n",
    "target = dataset['Churn']\n",
    "\n",
    "# Get categorical and numerical columns\n",
    "categorical_columns = features.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "features_encoded = pd.get_dummies(features, columns=categorical_columns)\n",
    "\n",
    "# Use stratified split to ensure both classes are represented in the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, stratify=target, random_state=42)\n",
    "\n",
    "# Check the distribution of the training labels to ensure balance\n",
    "print(\"Training set class distribution:\", y_train.value_counts(normalize=True))\n",
    "\n",
    "# Display the shape of training and test data\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.21%\n",
      "Confusion Matrix:\n",
      "[[906 129]\n",
      " [178 196]]\n"
     ]
    }
   ],
   "source": [
    "# Import SMOTE for oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the training dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the balanced data\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output model accuracy and confusion matrix\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: 78.21%\n",
    "The model achieved an accuracy of 78.21%, which means that it correctly predicted whether a customer would churn or not in 78.21% of the test cases. Accuracy alone may not fully represent model performance, especially when dealing with imbalanced datasets (like churn vs. non-churn), so we should also examine the confusion matrix for a deeper analysis.\n",
    "\n",
    "#### Confusion Matrix:\n",
    "The confusion matrix gives us detailed insights into the model's predictions:\n",
    "- 906 (True Negatives): The model correctly predicted 906 cases where the customer did not churn.\n",
    "- 129 (False Positives): The model incorrectly predicted 129 cases where the customer was predicted to churn, but in reality, they did not churn.\n",
    "- 178 (False Negatives): The model incorrectly predicted 178 cases where the customer was predicted to not churn, but in reality, they did churn.\n",
    "- 196 (True Positives): The model correctly predicted 196 cases where the customer did churn.\n",
    "\n",
    "#### Interpretation:\n",
    "- True Positives (196) and True Negatives (906) show that the model is correctly identifying a significant number of both churn and non-churn customers.\n",
    "- However, the number of False Negatives (178) is relatively high, which means the model is missing some customers who actually churned.\n",
    "- The False Positives (129) indicate cases where the model incorrectly predicted that customers would churn, but they did not.\n",
    "\n",
    "#### Model Performance:\n",
    "- While an accuracy of 78.21% is decent, the confusion matrix reveals that there is room for improvement in reducing false negatives (customers who churn but were predicted not to).\n",
    "- A potential next step could involve tuning the model further or trying other models to improve the precision and recall for the churned class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to telco_churn_rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "model_filename = 'telco_churn_rf_model.pkl'\n",
    "joblib.dump(rf_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict using the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# Make predictions on the test set with the loaded model\n",
    "loaded_model_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Mapping predictions to human-readable output\n",
    "prediction_labels = ['No Churn' if pred == 0 else 'Churn' for pred in loaded_model_predictions]\n",
    "\n",
    "# Display a few predictions in a more readable format\n",
    "for i, prediction in enumerate(prediction_labels[:500]):\n",
    "    print(f\"Sample {i+1}: {prediction}\")\n",
    "\n",
    "# Create a DataFrame with the test data and the corresponding predictions\n",
    "X_test_with_predictions = X_test.copy()\n",
    "X_test_with_predictions['Predicted Churn'] = loaded_model_predictions\n",
    "\n",
    "# Map the predictions to human-readable form\n",
    "X_test_with_predictions['Predicted Churn'] = X_test_with_predictions['Predicted Churn'].apply(lambda x: 'No Churn' if x == 0 else 'Churn')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file_path = 'prediction_customer_churn.csv'\n",
    "X_test_with_predictions.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path  # Return the path to the saved CSV file\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
